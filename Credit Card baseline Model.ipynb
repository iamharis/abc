{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IMXXGN2tcjIl"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 327,
     "status": "ok",
     "timestamp": 1584028612170,
     "user": {
      "displayName": "Hariskri Data",
      "photoUrl": "",
      "userId": "07998376272141531699"
     },
     "user_tz": 240
    },
    "id": "J8CPQQHOdguW",
    "outputId": "5b453502-8d22-4540-f033-6ba86b6269cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.config', 'drive', 'sample_data']"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lfc2A1A-eHaq"
   },
   "outputs": [],
   "source": [
    "file_path = 'creditcard.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RM7XGOS4di8e"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 530,
     "status": "ok",
     "timestamp": 1584028775294,
     "user": {
      "displayName": "Hariskri Data",
      "photoUrl": "",
      "userId": "07998376272141531699"
     },
     "user_tz": 240
    },
    "id": "Xt8iQyiqd86r",
    "outputId": "de334286-8078-4ab3-ab62-5580a71aa827"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
       "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62    0.0\n",
       "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69    0.0\n",
       "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66    0.0\n",
       "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50    0.0\n",
       "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99    0.0\n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 846,
     "status": "ok",
     "timestamp": 1584028779793,
     "user": {
      "displayName": "Hariskri Data",
      "photoUrl": "",
      "userId": "07998376272141531699"
     },
     "user_tz": 240
    },
    "id": "TCgGISzbeBow",
    "outputId": "58e6b04b-0a49-423d-e052-467ae6186de8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213969, 31)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 842,
     "status": "ok",
     "timestamp": 1584028794176,
     "user": {
      "displayName": "Hariskri Data",
      "photoUrl": "",
      "userId": "07998376272141531699"
     },
     "user_tz": 240
    },
    "id": "IugCimEreQFi",
    "outputId": "010fd849-b96a-48c5-b571-61e18effacc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        1\n",
       "V7        1\n",
       "V8        1\n",
       "V9        1\n",
       "V10       1\n",
       "V11       1\n",
       "V12       1\n",
       "V13       1\n",
       "V14       1\n",
       "V15       1\n",
       "V16       1\n",
       "V17       1\n",
       "V18       1\n",
       "V19       1\n",
       "V20       1\n",
       "V21       1\n",
       "V22       1\n",
       "V23       1\n",
       "V24       1\n",
       "V25       1\n",
       "V26       1\n",
       "V27       1\n",
       "V28       1\n",
       "Amount    1\n",
       "Class     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 949,
     "status": "ok",
     "timestamp": 1584031067360,
     "user": {
      "displayName": "Hariskri Data",
      "photoUrl": "",
      "userId": "07998376272141531699"
     },
     "user_tz": 240
    },
    "id": "MDQ6gPNVeTmq",
    "outputId": "778e2118-a3b7-4af5-ecf0-2cb9603f7c2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 213969 entries, 0 to 213968\n",
      "Data columns (total 31 columns):\n",
      "Time      213969 non-null float64\n",
      "V1        213969 non-null float64\n",
      "V2        213969 non-null float64\n",
      "V3        213969 non-null float64\n",
      "V4        213969 non-null float64\n",
      "V5        213969 non-null float64\n",
      "V6        213968 non-null float64\n",
      "V7        213968 non-null float64\n",
      "V8        213968 non-null float64\n",
      "V9        213968 non-null float64\n",
      "V10       213968 non-null float64\n",
      "V11       213968 non-null float64\n",
      "V12       213968 non-null float64\n",
      "V13       213968 non-null float64\n",
      "V14       213968 non-null float64\n",
      "V15       213968 non-null float64\n",
      "V16       213968 non-null float64\n",
      "V17       213968 non-null float64\n",
      "V18       213968 non-null float64\n",
      "V19       213968 non-null float64\n",
      "V20       213968 non-null float64\n",
      "V21       213968 non-null float64\n",
      "V22       213968 non-null float64\n",
      "V23       213968 non-null float64\n",
      "V24       213968 non-null float64\n",
      "V25       213968 non-null float64\n",
      "V26       213968 non-null float64\n",
      "V27       213968 non-null float64\n",
      "V28       213968 non-null float64\n",
      "Amount    213968 non-null float64\n",
      "Class     213968 non-null float64\n",
      "dtypes: float64(31)\n",
      "memory usage: 50.6 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 849,
     "status": "ok",
     "timestamp": 1584031100271,
     "user": {
      "displayName": "Hariskri Data",
      "photoUrl": "",
      "userId": "07998376272141531699"
     },
     "user_tz": 240
    },
    "id": "YI1lmVNym-i0",
    "outputId": "5f74b9e4-ebcd-4af2-b43b-48848e3698a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 95677\n",
      "V1 207817\n",
      "V2 207817\n",
      "V3 207817\n",
      "V4 207817\n",
      "V5 207817\n",
      "V6 207817\n",
      "V7 207817\n",
      "V8 207817\n",
      "V9 207817\n",
      "V10 207817\n",
      "V11 207817\n",
      "V12 207817\n",
      "V13 207817\n",
      "V14 207817\n",
      "V15 207817\n",
      "V16 207817\n",
      "V17 207817\n",
      "V18 207817\n",
      "V19 207817\n",
      "V20 207817\n",
      "V21 207817\n",
      "V22 207817\n",
      "V23 207817\n",
      "V24 207817\n",
      "V25 207817\n",
      "V26 207817\n",
      "V27 207817\n",
      "V28 207817\n",
      "Amount 28790\n",
      "Class 3\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    print(column, len(df[column].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K9UyQSBinWLl"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()\n",
    "# There doesnt seem to be obvious nulls\n",
    "\n",
    "# Non-obvious nulls such as blanks: The line items where there are spaces \n",
    "blank_space_col_list = []\n",
    "object_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "for col in object_columns:\n",
    "    print(col, sum(df[col]==' '))\n",
    "    if sum(df[col]==' '):\n",
    "        blank_space_col_list.append(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 364,
     "status": "ok",
     "timestamp": 1584031170890,
     "user": {
      "displayName": "Hariskri Data",
      "photoUrl": "",
      "userId": "07998376272141531699"
     },
     "user_tz": 240
    },
    "id": "MBz815gSnGnS",
    "outputId": "ab6f0378-1438-457f-fc7c-5d3f3d426a29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before dropping null values is 213968\n",
      "Number of rows after dropping null values is 213968\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Drop any columns that can cause trouble for now and come back to it in future iterations\n",
    "drop_column_list = []\n",
    "df.drop(drop_column_list, axis=1, inplace=True)\n",
    "\n",
    "df.head()\n",
    "\n",
    "# When you are short of time, be ruthless & clinical in treating edge cases and null values\n",
    "# For now, drop all the null rows instead of imputing them\n",
    "\n",
    "print('Number of rows before dropping null values is {}'.format(len(df)))\n",
    "\n",
    "# drop NaN rows\n",
    "df=df.dropna(axis=0)\n",
    "\n",
    "# drop rows with blank spaces identified previously\n",
    "for blank_col in blank_space_col_list:\n",
    "    df = df[df[blank_col]!=' ']\n",
    "\n",
    "print('Number of rows after dropping null values is {}'.format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1199,
     "status": "ok",
     "timestamp": 1584031195643,
     "user": {
      "displayName": "Hariskri Data",
      "photoUrl": "",
      "userId": "07998376272141531699"
     },
     "user_tz": 240
    },
    "id": "SsatKu8QnLMK",
    "outputId": "f923ccec-1493-48a3-ca49-5b261105ac54"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
       "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62    0.0\n",
       "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69    0.0\n",
       "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66    0.0\n",
       "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50    0.0\n",
       "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99    0.0\n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This step is needed if you want to convert all categorical columns to ordinal encoded numbers\n",
    "# Filter the above object columns based on the object data type\n",
    "\n",
    "object_columns = df.select_dtypes(include=['object']).columns\n",
    "df[object_columns].head()\n",
    "\n",
    "# This method of Label Encoding assumes that we are using Tree-based models later.\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Iterate through the object columns and convert them one by one into a numerical column\n",
    "for column in object_columns:\n",
    "    # Instantiate a labelencoder object and then do the fit transform on the data\n",
    "    labelencoder = LabelEncoder()\n",
    "    df[column] = labelencoder.fit_transform(df[column])\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ayAjP62zn32X"
   },
   "outputs": [],
   "source": [
    "target_class_name = \"Class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 359,
     "status": "ok",
     "timestamp": 1584031317288,
     "user": {
      "displayName": "Hariskri Data",
      "photoUrl": "",
      "userId": "07998376272141531699"
     },
     "user_tz": 240
    },
    "id": "79LrJTSlndz7",
    "outputId": "4116306d-5676-4ece-ec13-5501ec07cdd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of negative class is 99.814 %\n",
      "Percentage of Positive class is 0.186 %\n"
     ]
    }
   ],
   "source": [
    "# Figure out the class distribution percentage and round it to 3 decimal places\n",
    "\n",
    "print('Percentage of negative class is {} %'.format(\n",
    "    round(df[target_class_name].value_counts()[0]/len(df) * 100,3)))\n",
    "\n",
    "print('Percentage of Positive class is {} %'.format(\n",
    "    round(df[target_class_name].value_counts()[1]/len(df) * 100,3)))\n",
    "\n",
    "# Watch out for situations where the percentage of one class is really small compared to the other\n",
    "# In such a scenario we would need to use SMOTE or other balancing techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O0crRI6lnjwW"
   },
   "outputs": [],
   "source": [
    "X = df.drop(target_class_name, axis=1)\n",
    "y = df[target_class_name]\n",
    "\n",
    "# split into train and test set \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Note optionally convert the pandas dataframe into a numpy array using to_numpy if you have a big data\n",
    "# and want to model faster. Otherwise it doesnt matter which data structure you use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 162284,
     "status": "ok",
     "timestamp": 1584031494177,
     "user": {
      "displayName": "Hariskri Data",
      "photoUrl": "",
      "userId": "07998376272141531699"
     },
     "user_tz": 240
    },
    "id": "fJugGRijn8ds",
    "outputId": "107d77d5-8913-45c6-932f-0fa177f6c143"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has a training accuracy of 100.0 % \n",
      "Has a test accuracy of 99.967 % \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a classifier object with default params\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using both train and test set\n",
    "\n",
    "rf_train_pred = classifier.predict(X_train)\n",
    "rf_test_pred = classifier.predict(X_test)\n",
    "\n",
    "training_score = classifier.score(X_train, y_train)\n",
    "test_score = classifier.score(X_test, y_test)\n",
    "\n",
    "print(\"Has a training accuracy of {} % \".format(round(training_score.mean(), 5) * 100))\n",
    "print(\"Has a test accuracy of {} % \".format(round(test_score.mean(), 5) * 100))\n",
    "# The accuracy score on its own is less useful for classification. Need to check the confusion matrix\n",
    "# Notice how severe the overfitting is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 803,
     "status": "ok",
     "timestamp": 1584032914590,
     "user": {
      "displayName": "Hariskri Data",
      "photoUrl": "",
      "userId": "07998376272141531699"
     },
     "user_tz": 240
    },
    "id": "LRSKa8Dkn_Xm",
    "outputId": "f76c689f-26fc-45e1-f01f-213f13e91faf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    170854\n",
      "         1.0       1.00      1.00      1.00       320\n",
      "\n",
      "    accuracy                           1.00    171174\n",
      "   macro avg       1.00      1.00      1.00    171174\n",
      "weighted avg       1.00      1.00      1.00    171174\n",
      "\n",
      "Test Data report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     42716\n",
      "         1.0       1.00      0.82      0.90        78\n",
      "\n",
      "    accuracy                           1.00     42794\n",
      "   macro avg       1.00      0.91      0.95     42794\n",
      "weighted avg       1.00      1.00      1.00     42794\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"Train Data Report \\n\",classification_report(y_train, rf_train_pred))\n",
    "\n",
    "print(\"Test Data report \\n\", classification_report(y_test, rf_test_pred))\n",
    "# As can be seen in the report below, the F1 score can be improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D7A5_9Ertzaq"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "# This is from sklearn's example page \n",
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2167,
     "status": "ok",
     "timestamp": 1584032969141,
     "user": {
      "displayName": "Hariskri Data",
      "photoUrl": "",
      "userId": "07998376272141531699"
     },
     "user_tz": 240
    },
    "id": "U-jJlMUBuFUq",
    "outputId": "d7c272b9-602e-4f63-c6b2-6a9ed28ef291"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[42716     0]\n",
      " [   14    64]]\n",
      "\n",
      "\n",
      "Of the 42794 items in the Test set,\n",
      "The model correctly predicts 64 true positives while missing out on 14 false negatives\n",
      "It also picks up 0 false positives\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAEmCAYAAACzoiEDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naaqKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = [\"No\" , \"Yes\"]\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Call the function above for the....\n",
    "\n",
    "# training data \n",
    "confusion_matrix_train_object = confusion_matrix(y_train, rf_train_pred)\n",
    "\n",
    "# and\n",
    "\n",
    "# test data\n",
    "confusion_matrix_test_object = confusion_matrix(y_test, rf_test_pred)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "plot_confusion_matrix(confusion_matrix_test_object, labels, title=\"Test Confusion Matrix\", \n",
    "                      cmap=plt.cm.Oranges)\n",
    "\n",
    "print('\\n')\n",
    "tn, fp, fn, tp = confusion_matrix_test_object.ravel()\n",
    "print('Of the {} items in the Test set,'.format(len(y_test)))\n",
    "print('The model correctly predicts {} true positives while missing out on {} false negatives'.format(\n",
    "tp, fn))\n",
    "\n",
    "print('It also picks up {} false positives'.format(fp))\n",
    "\n",
    "# FP of  of  is pretty bad. \n",
    "# FN of  of  is also pretty bad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8bAT14i9uOjh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMo7R/dnqcfeLUloBulH588",
   "mount_file_id": "1pSgRrkgm92oxN1EPVYEZPkIun79PiSPl",
   "name": "Credit Card baseline Model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
